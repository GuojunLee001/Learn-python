## 从Web抓取信息

### 1. Web抓取常用模块

webbrower：打开浏览器获取指定页面。

requests：从网上下载文件和网页。

Beautiful Soup：解析HTML，即网页编写的格式。

Selenium：启动并控制浏览器，可以模拟鼠标在这个网页上点击。

### 2. 通过request模块下载Web文件

1. 调用 requests.get()下载该文件。

2. 用'wb'调用 open()，以写二进制的方式打开一个新文件。 

3. 利用 Respose 对象的 iter_content()方法做循环。 

4. 在每次迭代中调用 write()，将内容写入该文件。 

5. 调用 close()关闭该文件。

```python
# _*_ coding:utf-8 _*_

# 输入模块
import requests

res = requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')

# 检验是否下载成功
res.raise_for_status()

# 以写二进制的方式打开文件
playFile = open('RomeoAndJuliet.txt', 'wb')

# 通过循环克隆文件
for chunk in res.iter_content(1000000):
​    playFile.write(chunk)

# 关闭文件
playFile.close()
```

### 3. 用 BeautifulSoup 模块解析 HTML

BeautifulSoup 是用于从HTML页面中提取信息的模块。在这里，需要先搞明白HTML是什么。

####3.1 HTML简介

HTML全称Hypertext Marked Language，即超文本标记语言，由Web的发明者 Tim Berners-Lee和同事 Daniel W. Connolly于1991年创立。超文本标记语言利用统一规则把网页上的图文视音频统一在一个格式下面。从Web抓取信息需要先弄清楚HTML网页结构，以便寻找需要的信息，并制定抓取策略。

基本结构如下：

```HTML
<html><head><title>The Website Title</title></head>
<body>

<h1>我的第一个标题</h1>

<p>我的第一个段落。</p>

</body>
</html>
```

具有以下特征：

- 用<>表示
- 成对出现，第一个是开始标签，第二个是结束标签
- 纯文本文件，带有.html

那么如何发现网页的源代码呢？如果是谷歌浏览器可以直接右键单击`检查`，然后点击代码即可发现对应的网页内容。

#### 3.2 “I’m Feeling Lucky”Google 查找

代码目的：自动查找网页中所需的特定信息。

代码逻辑：

- 从命令行参数中获取查询关键字。
- 取得查询结果页面。 
- 为每个结果打开一个浏览器选项卡。

这意味着代码需要完成以下工作: 

- 从 sys.argv 中读取命令行参数。
- 用 requests 模块取得查询结果页面。
- 找到每个查询结果的链接。
- 调用 webbrowser.open()函数打开 Web 浏览器。 
- 打开一个新的文件编辑器窗口，并保存为 lucky.py。

Ref 《Python编程快速上手—让繁琐工作自动化》

2020nian 3月27日
